# Data Science - Day 5: Feature Engineering - Easy Questions

## 1. What is feature engineering?
**Answer:**  
Feature engineering is the process of creating, transforming, or selecting variables (features) to improve the performance of machine learning models.

---

## 2. Why is feature engineering important?
**Answer:**  
Good features can make simple models perform well, while poor features can make even complex models perform badly.

---

## 3. What is a feature in the context of machine learning?
**Answer:**  
A feature is an individual measurable property or input variable used to predict the target variable.

---

## 4. What is feature scaling?
**Answer:**  
Feature scaling transforms features to be on a similar scale, typically using normalization or standardization.

---

## 5. Name two common techniques used for encoding categorical features.
**Answer:**  
- One-hot encoding  
- Label encoding

---

## 6. What does one-hot encoding do?
**Answer:**  
It creates a new binary column for each category in a categorical variable, assigning 1 to the present category and 0 to others.

---

## 7. What is binning in feature engineering?
**Answer:**  
Binning groups continuous variables into discrete intervals or "bins" to simplify modeling or capture non-linearity.

---

## 8. What is a derived or constructed feature?
**Answer:**  
It's a new feature created from existing features (e.g., BMI = weight/heightÂ²).

---

## 9. What is the purpose of removing irrelevant features?
**Answer:**  
Irrelevant features add noise, increase complexity, and may reduce model accuracy.

---

## 10. What is missing value imputation?
**Answer:**  
It is the process of filling in missing values in a dataset using methods like mean, median, or most frequent value.
