# Intermediate Applied Mathematics for Data Science – Set 2

## Question 11: What is the curse of dimensionality, and how does it affect machine learning models?

**Answer**:  
The curse of dimensionality refers to the exponential increase in volume associated with adding extra dimensions to a dataset. As dimensions increase:

- Data becomes sparse.
- Distance metrics lose meaning.
- Models overfit more easily.

Solutions include dimensionality reduction (e.g., PCA), feature selection, and regularization.

---

## Question 12: What is a convex hull and how is it useful in data analysis?

**Answer**:  
A convex hull is the smallest convex set that encloses all points in a dataset. It is useful for:

- Outlier detection.
- Clustering boundaries.
- Understanding the shape and spread of data in multidimensional space.

---

## Question 13: Explain the difference between gradient descent and stochastic gradient descent (SGD).

**Answer**:  
- **Gradient Descent**: Uses the entire dataset to compute gradients and update parameters — slower but more stable.
- **SGD**: Uses one (or a few) samples to update weights per iteration — faster and more scalable, but introduces noise.

SGD is preferred for large datasets and online learning.

---

## Question 14: How is Bayes’ Theorem applied in spam detection?

**Answer**:  
Bayes’ Theorem allows computing the probability that an email is spam given the presence of certain words.  
\[ P(\text{Spam} \mid \text{Words}) = \frac{P(\text{Words} \mid \text{Spam}) \cdot P(\text{Spam})}{P(\text{Words})} \]

It's used in **Naïve Bayes classifiers**, which assume word independence.

---

## Question 15: What is the Moore-Penrose pseudoinverse, and why is it important?

**Answer**:  
The Moore-Penrose pseudoinverse is a generalization of the matrix inverse for non-square or singular matrices.  
Applications include:

- Solving linear systems \( Ax = b \) when \( A \) is not invertible.
- Least squares regression.
- Dimensionality reduction.

---

## Question 16: What is entropy in information theory, and how is it used in decision trees?

**Answer**:  
Entropy measures the uncertainty or impurity in a dataset:
\[ H(X) = -\sum p(x_i) \log p(x_i) \]

In decision trees, it's used to select features that reduce uncertainty the most (information gain). The lower the entropy after a split, the better the feature.

---

## Question 17: Explain the difference between a stationary and a non-stationary time series.

**Answer**:  
- **Stationary**: Mean, variance, and autocorrelation structure remain constant over time.
- **Non-stationary**: These properties change over time.

Stationarity is crucial for many models (ARIMA, etc.). Non-stationary series are typically transformed (e.g., via differencing) to become stationary.

---

## Question 18: What is the significance of the rank of a matrix?

**Answer**:  
The rank represents the number of linearly independent rows or columns. It determines:

- The solution type of linear systems.
- Whether a matrix is invertible (full rank).
- Data redundancy in feature matrices.

Low-rank approximations are useful in compression and recommendation systems.

---

## Question 19: What is Jensen’s Inequality and how does it apply to machine learning?

**Answer**:  
Jensen’s Inequality states:
For a convex function \( f \),  
\[ f(\mathbb{E}[X]) \leq \mathbb{E}[f(X)] \]

Applications:
- In EM algorithm derivation.
- Proving convergence properties.
- Bounding loss functions in probabilistic models.

---

## Question 20: What are Lagrange multipliers and when are they used?

**Answer**:  
Lagrange multipliers are used to find maxima or minima of a function subject to constraints.  
They help optimize:
- Loss functions with regularization.
- Constrained optimization in SVMs.
- Dual formulations in convex problems.

---
