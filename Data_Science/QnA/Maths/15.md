### Q8: How does eigenvalue decomposition help in understanding the variance in PCA (Principal Component Analysis)?

**Answer:**
Eigenvalue decomposition is at the core of PCA.  
When we compute the covariance matrix of the dataset and perform eigenvalue decomposition:

- **Eigenvectors** indicate the *directions* (principal components) along which the data varies the most.
- **Eigenvalues** indicate the *magnitude of variance* along each principal component.

In PCA:
1. The covariance matrix captures relationships between features.
2. Eigenvalue decomposition finds orthogonal directions where variance is maximized.
3. The eigenvector with the largest eigenvalue corresponds to the direction of greatest variance.
4. By selecting the top `k` eigenvectors (based on eigenvalues), we can reduce dimensionality while retaining most of the data's variance.

This process allows us to compress data, remove noise, and improve computational efficiency, while still preserving the key structure of the dataset.
