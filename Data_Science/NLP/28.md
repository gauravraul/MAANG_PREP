# Hard Level NLP Questions and Answers (Set 16)

### 1. How does masked language modeling (MLM) differ from causal language modeling (CLM)?
**Answer:**  
- **MLM (e.g., BERT):** Predicts randomly masked tokens, bidirectional context, good for understanding tasks.  
- **CLM (e.g., GPT):** Predicts next token in sequence, unidirectional, good for generation tasks.  

---

### 2. Why is positional encoding important in Transformers?
**Answer:**  
Transformers lack inherent sequence order awareness. Positional encodings inject sequential information, allowing models to differentiate "cat sat on mat" vs. "mat sat on cat."  

---

### 3. What is catastrophic forgetting in NLP models?
**Answer:**  
When fine-tuning on a new task, models forget previously learned tasks. This is mitigated using **Elastic Weight Consolidation (EWC)**, multi-task learning, or adapters.  

---

### 4. Explain tokenization challenges for morphologically rich languages.
**Answer:**  
Languages like Turkish or Finnish create long, complex words via inflections. Word-level tokenization explodes vocabulary. Solutions: **subword tokenization (BPE, WordPiece, SentencePiece)**.  

---

### 5. How do retrieval-augmented generation (RAG) models improve factual accuracy?
**Answer:**  
They fetch relevant passages from an external knowledge base before generation. This grounds outputs in retrieved text, reducing hallucinations.  

---

### 6. What are the trade-offs between dense and sparse embeddings?
**Answer:**  
- **Dense embeddings:** Compact, efficient, capture semantic similarity.  
- **Sparse embeddings (BM25, TF-IDF):** Interpretable, scalable, but weaker at capturing deep semantics. Hybrid methods combine both.  

---

### 7. How does curriculum learning apply to NLP?
**Answer:**  
It trains models starting with easier examples and gradually increasing difficulty. This improves convergence, robustness, and generalization.  

---

### 8. What is the role of attention masks in Transformers?
**Answer:**  
Attention masks prevent information leakage:  
- **Causal masks:** Ensure autoregressive models only see past tokens.  
- **Padding masks:** Prevent attention to padded tokens in batched inputs.  

---

### 9. How do large language models handle out-of-distribution (OOD) data?
**Answer:**  
Poorly, unless augmented with:  
- Retrieval (RAG)  
- Domain adaptation fine-tuning  
- Uncertainty estimation (Bayesian methods, ensembles)  

---

### 10. What is the significance of probing in NLP?
**Answer:**  
Probing inserts lightweight classifiers on hidden states to test what information (syntax, semantics, coreference) models capture internally, aiding interpretability and analysis.
