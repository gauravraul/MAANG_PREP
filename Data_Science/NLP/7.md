# Research-Level NLP Interview Questions – Set 3

## 1. What are the main challenges in grounding LLMs in external tools and APIs?
**Answer:**  
- **Dynamic context switching** between natural language and API instructions.  
- **Semantic parsing errors** (misinterpreting API parameters).  
- **Security risks** from prompt injection (malicious API calls).  
- **Latency trade-offs** when combining retrieval + API calls.  
Solutions: tool-use fine-tuning, structured output enforcement (e.g., JSON), and sandboxed execution.

---

## 2. How can we measure and mitigate hallucinations in open-domain LLMs?
**Answer:**  
- **Measurement**: Fact-checking via retrieval, entailment-based models, human annotation.  
- **Mitigation**:  
  - Retrieval-Augmented Generation (RAG).  
  - Knowledge graph grounding.  
  - Penalizing low-confidence generations via uncertainty modeling.  
  - Self-consistency: generating multiple outputs and choosing consensus.

---

## 3. Explain the concept of Compositional Generalization in NLP.
**Answer:**  
Models should generalize to novel combinations of known concepts (e.g., “red square on a green circle”).  
Problem: LLMs often memorize patterns instead of compositional reasoning.  
Solutions:  
- Training with synthetic compositional datasets (SCAN, COGS).  
- Neural-symbolic approaches.  
- Explicit program induction models.

---

## 4. What are the limitations of current evaluation benchmarks like GLUE, SuperGLUE, and HELM?
**Answer:**  
- Saturation: SOTA models surpass human-level performance, but fail in real-world settings.  
- Lack of robustness testing (adversarial attacks, OOD inputs).  
- Bias insensitivity (social, cultural).  
- Poor measurement of reasoning, grounding, and safety.  
Research is shifting toward **dynamic, task-agnostic benchmarks**.

---

## 5. What is the role of Causal Inference in modern NLP tasks?
**Answer:**  
- Standard LLMs capture correlations, not causation.  
- Causal inference helps in:  
  - Debiasing embeddings.  
  - Interpreting spurious correlations in datasets.  
  - Ensuring robustness under distribution shifts.  
- Techniques: Counterfactual data augmentation, causal graphs, and SCMs integrated with language models.

---

## 6. How do Multimodal LLMs align vision and text representations?
**Answer:**  
- **Joint embedding space** using contrastive losses (e.g., CLIP).  
- **Cross-modal attention** where vision tokens and text tokens attend to each other.  
- **Adapters** for modality-specific encoders.  
Challenges: grounding fine-grained semantics (e.g., “man holding a red umbrella”) and long-video reasoning.

---

## 7. What are the main difficulties in Controllability of LLMs?
**Answer:**  
- Ensuring LLMs follow style, tone, or constraints without drifting.  
- Avoiding unintended side effects when enforcing constraints.  
- Lack of interpretable control tokens.  
Solutions:  
- Prefix-tuning, control tokens, reward modeling.  
- Hybrid symbolic + neural constraints.

---

## 8. How does Curriculum Learning apply to training large NLP models?
**Answer:**  
- Train models on simpler tasks/datasets first, gradually increasing difficulty.  
- Benefits:  
  - Stabilizes training.  
  - Improves data efficiency.  
  - Enhances compositional reasoning.  
- Applied in machine translation, reasoning benchmarks, and code models.

---

## 9. What are Neuro-Symbolic Approaches in NLP?
**Answer:**  
They combine neural networks (pattern recognition) with symbolic reasoning (logic, rules).  
Examples:  
- Neural semantic parsing for SQL queries.  
- Commonsense reasoning via symbolic knowledge bases (ConceptNet + embeddings).  
Advantage: Interpretability + generalization.  
Limitation: Integration complexity.

---

## 10. What are the challenges of scaling LLM inference in production systems?
**Answer:**  
- **Latency**: Long-sequence attention is quadratic in cost.  
- **Memory**: KV cache grows with sequence length.  
- **Cost**: Running billions of parameters is expensive.  
- **Load balancing**: Multi-tenant inference.  
Mitigations:  
- Quantization, distillation.  
- Sparse attention & memory-efficient transformers.  
- Dynamic batching, caching strategies.
