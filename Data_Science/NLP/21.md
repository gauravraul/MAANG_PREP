## Q66: What is Retrieval-Augmented NLP, and how does it differ from standard NLP?

**Answer:**
- **Standard NLP:** Relies solely on pretrained parameters and fine-tuning.
- **Retrieval-Augmented NLP (RAG-style):**
  - Retrieves external documents at inference time.
  - Provides context dynamically instead of relying on memorization.
- **Benefits:**
  - Reduces hallucination.
  - Easier to update knowledge without retraining.
- **Challenge:** Latency, retrieval quality, and context-window management.

---

## Q67: How do reasoning chains (Chain-of-Thought) enhance NLP models?

**Answer:**
- **Chain-of-Thought (CoT):** Model generates intermediate reasoning steps before final output.
- **Advantages:**
  - Improves multi-step reasoning.
  - Helps with arithmetic, logical, and commonsense tasks.
- **Example:**
  - Q: “If Alice has 3 apples and gives 1 to Bob, how many left?”
  - CoT: Alice starts with 3 → gives 1 → left with 2.
- **Risks:** Longer outputs increase inference cost and chance of compounding errors.

---

## Q68: What is tool-augmented NLP, and why is it useful?

**Answer:**
- **Definition:** Equipping NLP models with external APIs/tools (calculators, search engines, code executors).
- **Use Cases:**
  - Math & symbolic reasoning → calculator.
  - Current events → web search.
  - Coding tasks → Python execution.
- **Example:** LLM answering “What is the derivative of sin(x)?” by calling a symbolic math tool.
- **Challenge:** Reliable tool selection, API orchestration, error handling.

---

## Q69: What is dynamic evaluation in NLP?

**Answer:**
- **Definition:** Adjusting model parameters or context at inference time based on test input distribution.
- **Techniques:**
  - Cache-based adaptation (storing frequent tokens).
  - Online fine-tuning on recent inputs.
- **Benefits:**
  - Better performance in domain-specific, evolving environments.
- **Trade-off:** Increases computational cost and risk of overfitting.

---

## Q70: How do large NLP models handle multi-hop reasoning?

**Answer:**
- **Multi-hop reasoning:** Answering questions requiring multiple inference steps across documents.
- **Approaches:**
  - **RAG + CoT:** Retrieve multiple documents and reason step-by-step.
  - **Graph reasoning:** Convert documents into entity-relationship graphs.
  - **Decomposition:** Split query into smaller sub-questions.
- **Challenge:** Maintaining consistency across hops.
- **Example:**  
  - Q: “Which university did the author of *The Selfish Gene* attend?”  
  - Requires: Author = Richard Dawkins → Dawkins attended Oxford.
