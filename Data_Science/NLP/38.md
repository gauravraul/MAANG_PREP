# Research-Level NLP / Multimodal AI / Speech Questions (Set 26)

## Q1. How do scaling laws in multimodal models differ from unimodal LLMs?
**A1.** Scaling laws in LLMs (loss ∝ N^−α) often hold cleanly, but in multimodal models:  
- Data scaling dominates more than parameter scaling.  
- Alignment loss between modalities introduces extra inefficiencies.  
- Adding modalities can lead to **non-monotonic returns** (performance dips before stabilizing).  

---

## Q2. What are grounding challenges in multimodal AI?
**A2.** Grounding means tying language to real-world concepts. Challenges include:  
- Ambiguity across modalities (e.g., “bank” in text vs. image).  
- Dataset biases (over-represented co-occurrences).  
- Lack of real-world interaction (most training data is static).  

---

## Q3. Why is “semantic drift” a critical issue in long-context multimodal reasoning?
**A3.** Semantic drift happens when the model gradually deviates from the intended concept in long reasoning chains.  
- It compounds across multiple modalities.  
- Leads to hallucinations (e.g., wrongly inferring missing objects).  
- Mitigation: retrieval anchoring, consistency constraints.  

---

## Q4. What role do sparse mixture-of-expert (MoE) architectures play in multimodal models?
**A4.** MoEs reduce computational cost by activating only a subset of experts.  
- For multimodal models: different experts can specialize per modality.  
- Challenge: routing instability and load imbalance across experts.  

---

## Q5. How does adversarial robustness differ in multimodal systems?
**A5.**  
- Text perturbations: prompt injection, paraphrasing.  
- Image perturbations: imperceptible pixel changes.  
- Speech perturbations: inaudible frequency manipulations.  
Multimodal fusion sometimes amplifies vulnerability instead of mitigating it.  

---

## Q6. Why is continual learning harder for multimodal AI than text-only LLMs?
**A6.**  
- Catastrophic forgetting across multiple modalities.  
- Inconsistent update rates (vision datasets vs. language corpora).  
- Cross-modal misalignment when updating only one modality.  

---

## Q7. How do interpretability methods differ for vision
