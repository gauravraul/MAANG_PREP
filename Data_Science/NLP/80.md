# **Set 64: Self-Driving Cars, Autonomous Navigation & Safety-Critical AI (Research-Level Questions)**

---

### **Q1. What are the main subsystems of a self-driving car architecture?**
**A1.**  
A full AV (Autonomous Vehicle) stack includes:  
1. **Perception** – object detection, tracking, semantic segmentation  
2. **Localization & Mapping** – SLAM, HD maps, GPS fusion  
3. **Prediction** – forecasting trajectories of agents  
4. **Planning** – generating safe, comfortable, goal-directed paths  
5. **Control** – steering, throttle, braking  
6. **Safety & Redundancy** – fail-safes, redundancy, monitoring  
Each subsystem must work reliably under diverse conditions for end-to-end autonomy.

---

### **Q2. Why is perception especially challenging in autonomous driving?**
**A2.**  
- Low-visibility (fog, rain, night)  
- Edge cases: rare objects or behaviors  
- Occlusions & partial visibility  
- Long-range detection requirements  
- Sensor fusion complexity  
The environment is unstructured and dynamic, demanding high robustness and generalization.

---

### **Q3. How does sensor fusion improve AV perception?**
**A3.**  
Sensor fusion combines **LIDAR**, **RADAR**, **cameras**, **IMU**, and **GPS**.  
Benefits:  
- LIDAR → precise geometry  
- Cameras → color/texture semantics  
- RADAR → robust under weather  
Fusion improves accuracy, redundancy, and reliability by offsetting individual sensor weaknesses.

---

### **Q4. What is the role of HD maps in self-driving systems?**
**A4.**  
HD maps contain centimeter-level details: lane boundaries, curvature, traffic signs, signals.  
They enable:  
- Precise localization  
- Predictive planning  
- Semantic context (e.g., “this is a merge zone”)  
However, HD maps require frequent updates and are costly to maintain.

---

### **Q5. How do prediction models work for traffic participants?**
**A5.**  
Prediction models forecast multi-modal future trajectories of cars, pedestrians, and cyclists using:  
- Motion models (CV, CA)  
- Deep sequence models (LSTM, GRU)  
- Transformer-based trajectory predictions  
- Social interaction models (e.g., Social-GAN)  
They capture intention and scene context to anticipate risky behaviors.

---

### **Q6. What is motion planning, and why is it difficult?**
**A6.**  
Motion planning determines a safe, comfortable route considering constraints:  
- Dynamic obstacles  
- Traffic rules  
- Road geometry  
- Kinematic limits  
The search space is enormous, requiring optimization under uncertainty.

---

### **Q7. What is the difference between path planning and behavior planning?**
**A7.**  
- **Behavior planning:** High-level decisions (merging, overtaking, yielding).  
- **Path planning:** Precise trajectory generation under kinematic and dynamic constraints.  
Behavior planning chooses *what* to do; path planning decides *how* to execute it.

---

### **Q8. What is "end-to-end self-driving,” and what are its limitations?**
**A8.**  
End-to-end systems learn a direct mapping from sensors → control actions using deep neural networks.  
Limitations:  
- Hard to interpret  
- Difficult to certify for safety  
- Prone to rare-case failure  
- Requires enormous diverse data  
Hybrid architectures (perception + planning + control) remain more reliable in practice.

---

### **Q9. How does uncertainty propagate in AV systems?**
**A9.**  
Uncertainty arises in perception (sensor noise), prediction (agent behavior), and planning (environment dynamics).  
AVs use:  
- Bayesian inference  
- Gaussian processes  
- Probabilistic trajectory forecasting  
- Uncertainty-aware MPC  
to quantify confidence and ensure safe decisions.

---

### **Q10. What are the biggest challenges in testing self-driving cars?**
**A10.**  
- The long-tail of rare events  
- Dangerous scenarios impossible to test in real life  
- Weather/lighting diversity  
- Large-scale simulation needs  
- Regulatory and ethical requirements  
Massive simulation environments (CARLA, LGSVL, Waymo Simulation) are used to overcome these challenges.

---

### **Q11. What is a “risk-aware planner”?**
**A11.**  
A planner that accounts for uncertainty and risk scores during trajectory generation.  
It prioritizes **minimizing collision risk**, even if the optimal route becomes suboptimal in terms of time or comfort.

---

### **Q12. What are the failure modes of self-driving perception models?**
**A12.**  
- False positives (hallucinating obstacles)  
- False negatives (missed detections)  
- Misclassification of pedestrians/cyclists  
- Domain shift (snow, construction zones)  
- Sensor malfunctions  
Robustness requires domain adaptation and redundancy.

---

### **Q13. How do AVs ensure safety in ambiguous or unseen scenarios?**
**A13.**  
- Conservative fallback policies  
- Hard constraints (emergency braking envelopes)  
- Scenario-based testing  
- Risk-aware modeling  
- Uncertainty bounds  
These systems prioritize safety over optimality.

---

### **Q14. What is fleet learning, and how does it help AVs improve?**
**A14.**  
Fleet learning aggregates experience from millions of vehicles to identify failure cases, rare events, and improvements.  
Used by Tesla, Waymo, Cruise; it accelerates learning at scale.

---

### **Q15. What is V2X communication?**
**A15.**  
Vehicle-to-Everything communication:  
- V2V (Vehicle ↔ Vehicle)  
- V2I (Vehicle ↔ Infrastructure)  
- V2P (Vehicle ↔ Pedestrian devices)  
Enables collaborative perception and safer decisions.

---

### **Q16. What is the role of formal verification in safety-critical AI?**
**A16.**  
Formal verification mathematically proves that system behavior meets safety requirements.  
Used for:  
- Collision avoidance guarantees  
- Control barrier functions  
- Fail-safe logic  
Critical for certification of autonomous systems.

---

### **Q17. Why is human–robot interaction important in self-driving cars?**
**A17.**  
AVs share roads with humans — understanding human cues (gaze, gestures, intent) is essential for safe interactions.  
Pedestrian intent prediction is core research.

---

### **Q18. What causes distribution shift in self-driving datasets?**
**A18.**  
- New road types  
- Rare weather conditions  
- Unseen traffic patterns  
- Construction zones  
- Sensor upgrades  
AV models must continuously adapt to such shifts.

---

### **Q19. How can adversarial attacks impact autonomous vehicles?**
**A19.**  
- Fake lane markings  
- Spoofed stop signs  
- LIDAR/RADAR interference  
- GPS spoofing  
Adversarial robustness is a core requirement for AV safety.

---

### **Q20. What are the most important future research directions in autonomous driving?**
**A20.**  
- End-to-end interpretable autonomy  
- Causal reasoning in prediction models  
- Uncertainty-aware planners  
- Simulation-first development ecosystems  
- Multi-agent cooperative driving  
- Fully open-world perception systems  

---

**Summary:**  
This set covers the **architecture, planning, prediction, safety, and reasoning challenges** behind next-generation autonomous driving and safety-critical AI systems.
