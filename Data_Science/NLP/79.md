# **Set 63: Robotics Reasoning, Planning & Autonomous Control Systems (Research-Level Questions)**

---

### **Q1. What is hierarchical planning in robotics, and why is it important?**
**A1.**  
Hierarchical planning decomposes complex tasks into multiple levels:  
- **High-level goals** (e.g., “clean the table”)  
- **Mid-level subgoals** (e.g., “pick up plates”)  
- **Low-level motor actions** (e.g., “close gripper,” “extend arm”)  
It improves efficiency, interpretability, and generalization by separating strategic reasoning from motor control.

---

### **Q2. What is the difference between symbolic planning and motion planning?**
**A2.**  
- **Symbolic planning:** Uses logical rules and high-level reasoning (PDDL, STRIPS) to determine *what* to do.  
- **Motion planning:** Computes feasible collision-free trajectories in continuous space (RRT*, CHOMP, TrajOpt) to determine *how* to do it.  
Modern robotics integrates both for holistic decision-making.

---

### **Q3. How do behavior trees compare to finite state machines for robot control?**
**A3.**  
Behavior trees provide:  
- Modular and reusable behaviors  
- Hierarchical decision structure  
- Robust fallback mechanisms  
They scale better than finite state machines, which become brittle and exponential in complexity for large tasks.

---

### **Q4. What are task and motion planning (TAMP) systems?**
**A4.**  
TAMP integrates symbolic planning (logic reasoning) with motion planning (trajectory generation).  
Example:  
> “Pick the cup → navigate to sink → place cup inside → turn on faucet.”  
The system ensures logical validity and physical feasibility simultaneously.

---

### **Q5. How do modern robots perform long-horizon planning?**
**A5.**  
Through:  
- **World models** for future state prediction  
- **Hierarchical RL**  
- **Decomposition of tasks** into subtasks  
- **Look-ahead search** (Monte Carlo Tree Search, A*, RRT)  
Long-horizon planning requires temporal abstraction and state-space compression.

---

### **Q6. What role does multimodal reasoning play in autonomous robot control?**
**A6.**  
Robots integrate:  
- Vision (object identification)  
- Language (instruction understanding)  
- Proprioception (internal state)  
- Tactile feedback (contact detection)  
Multimodal fusion supports grounded, context-aware reasoning required for safe manipulation and navigation.

---

### **Q7. What is model predictive control (MPC), and why is it widely used?**
**A7.**  
MPC optimizes control actions over a prediction horizon, executing only the first action before re-optimizing.  
Benefits:  
- Robust to uncertainties  
- Handles constraints (collision, stability)  
- Enables real-time adaptation  
Used in drones, self-driving cars, and industrial robots.

---

### **Q8. What are kinodynamic constraints in robot planning?**
**A8.**  
Kinodynamic constraints combine **kinematics** (geometric limits like joint ranges) with **dynamics** (velocity, acceleration, torque limits).  
Realistic planning must satisfy both to ensure the robot can execute planned trajectories physically.

---

### **Q9. How does a robot maintain safety while operating near humans?**
**A9.**  
- Human pose estimation  
- Predictive collision avoidance  
- Safety zones & dynamic speed scaling  
- Tactile or force-feedback sensors  
- Formal safety guarantees (control barrier functions)  
Collaborative robots (cobots) rely heavily on these features.

---

### **Q10. What is reactive planning in robotics?**
**A10.**  
Reactive planning uses real-time sensor feedback to adjust actions dynamically — ideal for environments with uncertainty or moving obstacles.  
Contrasts with static planning, which cannot adapt to deviations or surprises.

---

### **Q11. How do robots use graph-based SLAM?**
**A11.**  
Graph-based SLAM creates a graph where nodes represent robot poses and edges represent sensor constraints.  
Optimization (e.g., g2o, Ceres) finds the most consistent map and trajectory.  
This allows autonomous navigation without GPS.

---

### **Q12. What is the difference between end-to-end and modular robotics control architectures?**
**A12.**  
- **End-to-end:** Maps sensors → actions directly (e.g., deep RL).  
- **Modular:** Separates perception, planning, and control.  
End-to-end is flexible but hard to interpret; modular is more reliable and explainable.

---

### **Q13. What is inverse reinforcement learning (IRL) in robotics?**
**A13.**  
IRL infers a hidden reward function based on expert demonstrations — allowing robots to learn *why* a behavior is optimal, not just *how* to mimic it.  
Useful in surgical robots, autonomous driving, and skill learning.

---

### **Q14. How do LLMs integrate with robotic planning pipelines?**
**A14.**  
LLMs handle:  
- Task parsing from natural language  
- High-level symbolic planning  
- Sequencing actions  
Robotics controllers handle low-level execution.  
LLMs act as the “brain,” while traditional control systems act as the “body.”

---

### **Q15. Why is contact-rich manipulation difficult in robotics?**
**A15.**  
Tasks like turning valves or inserting keys require:  
- Millimeter precision  
- High-frequency tactile feedback  
- Predicting friction and compliance  
- Stable force control  
These are hard for pure vision-based systems.

---

### **Q16. What is whole-body control in humanoids?**
**A16.**  
Whole-body control coordinates all joints simultaneously to maintain balance, manipulate objects, and react to disturbances.  
It uses torque-based optimization and dynamic modeling of the entire body.

---

### **Q17. What are learned dynamics models, and why are they useful?**
**A17.**  
Robots can learn approximate physics models directly from experience.  
Benefits:  
- Better adaptation to wear-and-tear  
- Handling unknown friction or loads  
- Improving long-term performance  
Used in locomotion and adaptive manipulation.

---

### **Q18. What is the role of control barrier functions (CBFs)?**
**A18.**  
CBFs enforce **safety constraints** mathematically during real-time control.  
They guarantee the robot will not enter unsafe states (e.g., collisions), even if the high-level policy fails.

---

### **Q19. How do robots handle multi-step task decomposition?**
**A19.**  
Using:  
- Hierarchical RL (options framework)  
- Task graphs  
- Language-driven decomposition via LLMs  
This allows robots to execute long sequences of interdependent actions.

---

### **Q20. What are the grand challenges in autonomous robotic reasoning?**
**A20.**  
- Long-horizon planning with uncertainty  
- Physical grounding of language  
- Robust contact-rich manipulation  
- Multi-agent coordination  
- Safety under distribution shift  
- Lifelong adaptation and learning  
These define the frontier of real-world autonomous robots.

---

**Summary:**  
This set covers the deep mechanics of **robotic planning, reasoning, safety, control, and multimodal intelligence** — the foundations of autonomous machines capable of operating reliably in the real world.
