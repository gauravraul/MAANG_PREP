# Intermediate Computer Vision Questions & Answers (Set 2)

### Q1. What is the difference between image classification, object detection, and semantic segmentation?
**A1.**  
- **Image classification** → Predicts a single label for the whole image.  
- **Object detection** → Identifies multiple objects with bounding boxes.  
- **Semantic segmentation** → Classifies each pixel into a category (no object distinction).  
- **Instance segmentation** → Combines object detection + semantic segmentation (separates instances of same class).

---

### Q2. Explain the role of receptive field in CNNs.
**A2.**  
The **receptive field** is the region of the input image that affects the output of a particular neuron in a CNN. Larger receptive fields capture more **global context** (e.g., object shape), while smaller receptive fields capture **local patterns** (e.g., edges, textures).

---

### Q3. What is the vanishing gradient problem in deep CNNs?
**A3.**  
In deep networks, during backpropagation, gradients can become very small and "vanish," preventing effective weight updates.  
- **Causes**: Deep layers, saturating activation functions (sigmoid, tanh).  
- **Solutions**: ReLU activations, residual connections (ResNet), batch normalization.

---

### Q4. What are dilated (atrous) convolutions?
**A4.**  
Dilated convolutions introduce "gaps" between kernel elements to increase the **receptive field** without increasing parameters. They are widely used in **semantic segmentation** (e.g., DeepLab).

---

### Q5. What is the difference between SSD, YOLO, and Faster R-CNN?
**A5.**  
- **Faster R-CNN** → Two-stage detector (region proposal + classification). More accurate, slower.  
- **YOLO** → Single-shot detector, fast, good for real-time applications.  
- **SSD** → Single-shot, uses multiple feature maps at different scales, balances speed & accuracy.

---

### Q6. Explain Non-Maximum Suppression (NMS) in object detection.
**A6.**  
NMS removes redundant bounding boxes for the same object:  
1. Sort boxes by confidence score.  
2. Select the highest confidence box.  
3. Remove boxes with high IoU overlap.  
4. Repeat until no boxes remain.

---

### Q7. What are key differences between CNNs and Vision Transformers (ViTs)?
**A7.**  
- **CNNs** → Good at local feature extraction, translation invariance.  
- **ViTs** → Use self-attention to capture global dependencies, require large datasets.  
- ViTs outperform CNNs on very large-scale data but CNNs perform better on small datasets.

---

### Q8. What is transfer learning in computer vision?
**A8.**  
Using a pretrained model (e.g., ResNet, VGG, EfficientNet) trained on a large dataset like ImageNet and fine-tuning it for a new, smaller dataset.  
Benefits: Faster training, fewer data requirements, better performance.

---

### Q9. How does Optical Flow work?
**A9.**  
Optical flow estimates the **apparent motion** of objects between consecutive frames.  
- Assumes pixel intensities remain constant across frames.  
- Used in action recognition, video stabilization, motion tracking.

---

### Q10. What are common challenges in computer vision?
**A10.**  
- Variations in lighting, scale, orientation.  
- Occlusion of objects.  
- Domain shift (training vs real-world data).  
- Large computational requirements.  
- Data annotation costs.
