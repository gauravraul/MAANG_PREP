# Hard-Level Computer Vision Questions and Answers (Set 3)

---

### 1. What are Vision Transformers (ViTs), and how do they differ from CNNs?
**Answer:**
- Vision Transformers use **self-attention mechanisms** instead of convolutions.
- They treat an image as a sequence of patches, similar to words in NLP.
- Unlike CNNs, which capture **local spatial hierarchies**, ViTs can model **global dependencies** from the start.
- Require **large-scale datasets** and **heavy computation** but show competitive or better performance.

---

### 2. Explain the concept of Neural Radiance Fields (NeRFs).
**Answer:**
- NeRFs represent 3D scenes as a continuous function parameterized by a neural network.
- They take in a **3D coordinate** and **viewing direction** and output the **color and density** at that point.
- Used for **novel view synthesis** and **3D reconstruction** from 2D images.
- Challenges: computationally expensive and require many input views.

---

### 3. How does Contrastive Learning work in Self-Supervised Vision tasks?
**Answer:**
- Contrastive Learning aims to bring **positive pairs (different augmentations of the same image)** closer and push **negative pairs (different images)** apart in embedding space.
- Example: **SimCLR** uses random augmentations and InfoNCE loss.
- Benefits: Removes need for labeled data while learning strong representations.
- Limitation: Needs **large batch sizes** or memory banks to perform well.

---

### 4. What is Panoptic Segmentation, and how is it different from Semantic and Instance Segmentation?
**Answer:**
- **Semantic Segmentation**: Classifies each pixel (e.g., road, sky, person).
- **Instance Segmentation**: Distinguishes individual objects (e.g., person 1, person 2).
- **Panoptic Segmentation**: Combines both â€” every pixel gets a **semantic label** and, for countable objects, an **instance ID**.
- Example architectures: **Panoptic FPN**, **Detectron2 Panoptic**.

---

### 5. How does Differentiable Rendering contribute to Computer Vision?
**Answer:**
- Differentiable Rendering allows gradients to flow from 2D images back to **3D representations**.
- Enables training neural networks for **inverse graphics problems** (inferring 3D structure from 2D).
- Core idea: make rendering pipelines differentiable.
- Applications: **3D reconstruction, NeRFs, inverse rendering**.

---

### 6. What is Visual Question Answering (VQA), and how is it solved?
**Answer:**
- VQA is the task of answering natural language questions about an image.
- Requires **multi-modal learning** (Vision + Language).
- Typical approach:
  - Extract visual features using **CNN/ViT**.
  - Encode question using **RNN/Transformer**.
  - Use **fusion mechanisms** (attention, multimodal transformers) to combine.
- Example datasets: **VQA v2, GQA**.

---

### 7. How does Optical Flow estimation work, and where is it used?
**Answer:**
- Optical Flow estimates the **pixel-wise motion** between two consecutive frames.
- Methods:
  - Classical: Horn-Schunck, Lucas-Kanade.
  - Deep Learning: FlowNet, RAFT.
- Applications: **video stabilization, motion tracking, action recognition, autonomous driving**.

---

### 8. Explain Domain Adaptation in Computer Vision.
**Answer:**
- Domain Adaptation deals with transferring knowledge from a **source domain** (e.g., synthetic images) to a **target domain** (e.g., real images).
- Approaches:
  - **Feature alignment** (adversarial training, e.g., DANN).
  - **Style transfer** (e.g., CycleGAN).
  - **Self-training** with pseudo-labels.
- Useful in robotics, medical imaging, and scenarios with limited real-world data.

---

### 9. What are Diffusion Models in Vision, and how do they generate images?
**Answer:**
- Diffusion models start with **noise** and iteratively denoise to generate images.
- They learn the reverse process of a **Markov chain of noise addition**.
- Popular models: **DDPM, Stable Diffusion**.
- Outperform GANs in stability and image quality, but require more compute.

---

### 10. How is Federated Learning applied in Computer Vision?
**Answer:**
- Federated Learning allows training on **decentralized data** (e.g., mobile devices) without sharing raw data.
- Each client trains locally, and model updates are aggregated at a server.
- Challenges: **non-IID data, communication overhead, privacy concerns**.
- Applications: **medical imaging, mobile photo enhancement, surveillance**.

---
