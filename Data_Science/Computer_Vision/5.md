# Intermediate Computer Vision Questions & Answers

## Q1. What is the difference between semantic segmentation and instance segmentation?
**Answer:**  
- **Semantic Segmentation:** Classifies each pixel into a category (e.g., road, car, tree). It does not distinguish between different instances of the same object.  
- **Instance Segmentation:** Identifies object boundaries for each individual object instance (e.g., two cars are segmented separately).  

---

## Q2. What are convolutional filters, and why are they used in CNNs?
**Answer:**  
Convolutional filters (kernels) are small matrices that slide over the input image to detect features like edges, textures, and shapes.  
- Early layers: Detect low-level features (edges, corners).  
- Deeper layers: Detect high-level features (faces, objects).  

---

## Q3. How does data augmentation improve computer vision models?
**Answer:**  
Data augmentation artificially increases dataset size and diversity by applying transformations like rotation, flipping, cropping, and color jittering.  
- Prevents overfitting.  
- Improves model generalization.  
- Helps simulate real-world variations.  

---

## Q4. What is Non-Maximum Suppression (NMS) in object detection?
**Answer:**  
NMS is a technique used to remove redundant bounding boxes.  
Steps:  
1. Select the bounding box with the highest confidence score.  
2. Remove other boxes with IoU (Intersection over Union) greater than a threshold.  
3. Repeat until no boxes remain.  

---

## Q5. How do you evaluate the performance of an object detection model?
**Answer:**  
- **Precision & Recall**  
- **IoU (Intersection over Union)**  
- **mAP (mean Average Precision)** â€“ widely used benchmark for detection.  
- **F1 Score** for balancing precision and recall.  

---

## Q6. What is the difference between CNNs and Vision Transformers (ViTs)?
**Answer:**  
- **CNNs:** Use convolutions to capture local spatial features. Great for smaller datasets.  
- **Vision Transformers:** Use self-attention to model long-range dependencies across an image. Require large datasets but often outperform CNNs on large-scale vision tasks.  

---

## Q7. What is transfer learning in computer vision?
**Answer:**  
Transfer learning uses pre-trained models (e.g., ResNet, VGG, EfficientNet) trained on large datasets like ImageNet.  
- You fine-tune or freeze layers and retrain on a smaller dataset.  
- Saves training time and improves performance on limited data.  

---

## Q8. Explain the difference between classification and detection in computer vision.
**Answer:**  
- **Classification:** Assigns a single label to an image (e.g., "cat").  
- **Detection:** Identifies and localizes multiple objects in an image with bounding boxes (e.g., "cat at (x1,y1,x2,y2)").  

---

## Q9. What are the main challenges in computer vision?
**Answer:**  
- Illumination changes.  
- Occlusion (objects blocking each other).  
- Scale variations (objects appearing at different sizes).  
- Domain adaptation (model not generalizing well to new data).  
- Real-time processing constraints.  

---

## Q10. What is optical flow, and where is it used?
**Answer:**  
Optical flow represents the apparent motion of pixels between consecutive video frames.  
- Used in motion detection, video compression, object tracking, and action recognition.  
- Algorithms: Lucas-Kanade, Horn-Schunck, and modern deep learning-based approaches.
