# Intermediate Computer Vision Questions and Answers (Set 3)

### 1. What is the difference between CNN and Fully Connected Networks in computer vision?
**Answer:**  
- CNNs use convolutional layers that capture spatial hierarchies and local patterns.  
- Fully connected networks treat every input pixel as independent, losing spatial information.  
- CNNs are more efficient and effective for image tasks.

---

### 2. Why is padding used in convolutional layers?
**Answer:**  
Padding is used to:  
1. Preserve spatial dimensions after convolution.  
2. Avoid shrinking the image after multiple layers.  
3. Ensure that corner and edge pixels get equal importance.  
Common types: **same padding** (output size = input size) and **valid padding** (no padding).

---

### 3. What is the receptive field in CNNs?
**Answer:**  
The receptive field is the region of the input image that affects a particular feature in deeper layers.  
- Larger receptive fields allow capturing global context.  
- Smaller receptive fields capture fine details.

---

### 4. How does Batch Normalization help in computer vision models?
**Answer:**  
Batch Normalization:  
- Normalizes activations across a mini-batch.  
- Reduces internal covariate shift.  
- Helps faster training, prevents vanishing/exploding gradients, and provides slight regularization.

---

### 5. Explain the difference between max pooling and average pooling.
**Answer:**  
- **Max pooling:** Takes the maximum value in a region → captures prominent features.  
- **Average pooling:** Takes the average of values in a region → smooths representations.  
Max pooling is used more in practice as it preserves strong features.

---

### 6. What is transfer learning in computer vision?
**Answer:**  
Transfer learning is using a pretrained model (like ResNet, VGG, EfficientNet) trained on a large dataset (e.g., ImageNet) and fine-tuning it on a smaller dataset.  
Benefits: faster training, requires less data, higher accuracy.

---

### 7. Why is data augmentation important in computer vision?
**Answer:**  
Data augmentation increases dataset diversity by applying transformations such as rotation, flipping, scaling, cropping, and color jitter.  
It prevents overfitting and improves generalization.

---

### 8. What is the difference between semantic segmentation and instance segmentation?
**Answer:**  
- **Semantic segmentation:** Classifies each pixel into a category but doesn’t differentiate between instances.  
- **Instance segmentation:** Identifies each object separately, even if they belong to the same class. (e.g., Mask R-CNN).

---

### 9. What is the vanishing gradient problem in deep vision networks?
**Answer:**  
In very deep networks, gradients shrink during backpropagation, making earlier layers learn very slowly.  
Solutions: ReLU activations, batch normalization, residual connections (ResNets).

---

### 10. How do residual connections (ResNets) help in computer vision?
**Answer:**  
Residual connections add shortcut paths that bypass one or more layers.  
- Prevents vanishing gradients.  
- Makes training deep networks (100+ layers) feasible.  
- Helps the network learn identity mappings easily.
